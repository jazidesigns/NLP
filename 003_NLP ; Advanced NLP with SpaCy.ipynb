{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95330917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the name of Allah, the Most Benoficient, the Most Merciful\n"
     ]
    }
   ],
   "source": [
    "Tasmia = \"In the name of Allah, the Most Benoficient, the Most Merciful\"\n",
    "print(Tasmia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0370a9a8",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6366f25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "from spacy.lang.en import English\n",
    "import re\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "import nlp\n",
    "import spacy\n",
    "from spacy.matcher import matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be83600",
   "metadata": {},
   "source": [
    "### Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61697cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Text.\n"
     ]
    }
   ],
   "source": [
    "nlp = English()\n",
    "\n",
    "doc = nlp(\"This is a Text.\")\n",
    "\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de89785b",
   "metadata": {},
   "source": [
    "**Print First Token**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1579ca61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n"
     ]
    }
   ],
   "source": [
    "nlp = English()\n",
    "\n",
    "doc = nlp(\"I like tree kangaroos and narwhals.\")\n",
    "\n",
    "print(doc[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4557eda2",
   "metadata": {},
   "source": [
    "**Extract Percentages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d5365e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"In 1990, more than 60% of people in East Asia were in extreme poverty. Now less than 4% are.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "915d545b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['60%', '4%']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find Percentages\n",
    "pattern = r'\\d+%'\n",
    "\n",
    "re.findall(pattern, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559d710",
   "metadata": {},
   "source": [
    "### Statistical Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e71d5afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He PRON\n",
      "ate VERB\n",
      "a DET\n",
      "pizza NOUN\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"He ate a pizza\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc6a53b",
   "metadata": {},
   "source": [
    "**Predicting Named Entities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "639e522d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "UK GPE\n",
      "$1 billion MONEY\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking to buy a UK startup for $1 billion\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43accbe",
   "metadata": {},
   "source": [
    "**Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "521900c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c640eb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8627203210548107"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = nlp(\"I like fast food\")\n",
    "doc2 = nlp(\"I like pizza\")\n",
    "\n",
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdd1f2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22325327"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"TV and Books\")\n",
    "\n",
    "token1, token2 = doc[0], doc[2]\n",
    "\n",
    "# Get the similarity of the tokens \"TV\" and \"books\"\n",
    "similarity = token1.similarity(token2)\n",
    "similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e967763",
   "metadata": {},
   "source": [
    "### Creating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4cff3490",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9876303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['How to preorder the iPhone X',\n",
    " 'iPhone X is coming',\n",
    " 'Should I pay $1,000 for the iPhone X?',\n",
    " 'The iPhone 8 reviews are here',\n",
    " 'Your iPhone goes up to 11 today',\n",
    " 'I need a new phone! Any tips?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e303d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two tokens whose lowercase forms match 'iphone' and 'x'\n",
    "pattern1 = [{'LOWER': 'iphone'}, {'LOWER': 'x'}]\n",
    "\n",
    "# Token whose lowercase form matches 'iphone' and an optional digit\n",
    "pattern2 = [{'LOWER': 'iphone'}, {'IS_DIGIT': True, 'OP': '?'}]\n",
    "\n",
    "# Add patterns to the matcher\n",
    "matcher.add('GADGET',[pattern1, pattern1],on_match = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85b23f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to preorder the iPhone X [(4, 6, 'GADGET')]\n",
      "iPhone X is coming [(0, 2, 'GADGET')]\n",
      "Should I pay $1,000 for the iPhone X? [(7, 9, 'GADGET')]\n",
      "The iPhone 8 reviews are here []\n",
      "Your iPhone goes up to 11 today []\n",
      "I need a new phone! Any tips? []\n"
     ]
    }
   ],
   "source": [
    "# Create a Doc object for each text in TEXTS\n",
    "for doc in nlp.pipe(text):\n",
    "    # Find the matches in the doc\n",
    "    matches = matcher(doc)\n",
    "    \n",
    "    # Get a list of (start, end, label) tuples of matches in the text\n",
    "    entities = [(start, end, 'GADGET') for match_id, start, end in matches]\n",
    "    print(doc.text, entities)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "561e955a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('How to preorder the iPhone X', {'entities': [(20, 28, 'GADGET')]})\n",
      "('iPhone X is coming', {'entities': [(0, 8, 'GADGET')]})\n",
      "('Should I pay $1,000 for the iPhone X?', {'entities': [(28, 36, 'GADGET')]})\n",
      "('The iPhone 8 reviews are here', {'entities': []})\n",
      "('Your iPhone goes up to 11 today', {'entities': []})\n",
      "('I need a new phone! Any tips?', {'entities': []})\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DATA = []\n",
    "\n",
    "# Create a Doc object for each text in TEXTS\n",
    "for doc in nlp.pipe(text):\n",
    "    # Match on the doc and create a list of matched spans\n",
    "    spans = [doc[start:end] for match_id, start, end in matcher(doc)]\n",
    "    # Get (start character, end character, label) tuples of matches\n",
    "    entities = [(span.start_char, span.end_char, 'GADGET') for span in spans]\n",
    "    \n",
    "    # Format the matches as a (doc.text, entities) tuple\n",
    "    training_example = (doc.text, {'entities': entities})\n",
    "    # Append the example to the training data\n",
    "    TRAINING_DATA.append(training_example)\n",
    "    \n",
    "print(*TRAINING_DATA, sep='\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9f3e41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
