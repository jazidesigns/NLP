{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f380cd11",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79e06d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import enchant\n",
    "import re\n",
    "from spellchecker import SpellChecker\n",
    "from autocorrect import Speller\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d573ee8",
   "metadata": {},
   "source": [
    "**1. Text Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68c6325e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'cat', 'is', 'sitting', 'on', 'the', 'mat', '.']\n"
     ]
    }
   ],
   "source": [
    "# Load spacy model\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# text\n",
    "text = \"The cat is sitting on the mat.\"\n",
    "\n",
    "# Load text in spacy model\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract tokens\n",
    "tokens = [token.text for token in doc]\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b0d4c0",
   "metadata": {},
   "source": [
    "**2. Lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14f50d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing ( NLP ) be a field of artificial intelligence ( AI ) that focus on the interaction between computer and human language . it involve the study and development of computational model and algorithm to enable computer to understand , interpret , and generate human language .\n"
     ]
    }
   ],
   "source": [
    "# Text for which we have to do lemmatization\n",
    "text = \"Natural Language Processing (NLP) is a field of artificial intelligence (AI) that focuses on the interaction between computers and human language. It involves the study and development of computational models and algorithms to enable computers to understand, interpret, and generate human language.\"\n",
    "\n",
    "# fit text into spacy model\n",
    "doc = nlp(text)\n",
    "\n",
    "# Lemmatization \n",
    "lemmatized_word = \" \".join([token.lemma_ for token in doc])\n",
    "print(lemmatized_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962883bf",
   "metadata": {},
   "source": [
    "**3. Lowercasing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9493ef45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "natural language processing (nlp) is a field of artificial intelligence (ai) that focuses on the interaction between computers and human language. it involves the study and development of computational models and algorithms to enable computers to understand, interpret, and generate human language.\n"
     ]
    }
   ],
   "source": [
    "lowercased_text = text.lower()\n",
    "print(lowercased_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f80419",
   "metadata": {},
   "source": [
    "**4. Stopwords Removel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "271715ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'field', 'artificial', 'intelligence', '(', 'AI', ')', 'focuses', 'interaction', 'computers', 'human', 'language', '.', 'involves', 'study', 'development', 'computational', 'models', 'algorithms', 'enable', 'computers', 'understand', ',', 'interpret', ',', 'generate', 'human', 'language', '.']\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words from the processed document\n",
    "filtered_tokens = [token.text for token in doc if not token.is_stop]\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb803a0",
   "metadata": {},
   "source": [
    "**5. Removing special characters and numbers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "881cf0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example sentence It includes special characters and numbers\n"
     ]
    }
   ],
   "source": [
    "# Special numbers and characters\n",
    "special = \"This is an example sentence! It includes 123 special characters *&^% and numbers 456.\"\n",
    "\n",
    "# Fit text into spacy\n",
    "doc = nlp(special)\n",
    "\n",
    "# Get the clean tokens without special characters and numbers. Is_alpha will only keep alphabetic characters\n",
    "clean_tokens = [token.text for token in doc if token.is_alpha or token.is_space]\n",
    "\n",
    "# Join the clean tokens to form the clean text\n",
    "clean_text = ' '.join(clean_tokens)\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4add35",
   "metadata": {},
   "source": [
    "**6. Handling spelling errors and abbreviations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32c7d5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thiss is a paragraff containing mispelled wrds. The sciense of NLP is an importannt feeld of AI. It involves prosessing, underrstanding, and generting human language text. NLP technolojies have a wied range of apllications, includding machine transletion, sentiment anallisis, and informasion retrieval. Machene Learneng is a powerful tool that can bee used to extract insiights from large amouts of data. It is widly used in varius industries such as healthcare, fainance, and marketting. The potentshal of ML is enormus, and it continus to evolv and advanse. With contnued reserch and innvation, we can unlok new possiblities and advans our understatding of the world.\n"
     ]
    }
   ],
   "source": [
    "paragraph = \"Thiss is a paragraff containing mispelled wrds. The sciense of NLP is an importannt feeld of AI. It involves prosessing, underrstanding, and generting human language text. NLP technolojies have a wied range of apllications, includding machine transletion, sentiment anallisis, and informasion retrieval. Machene Learneng is a powerful tool that can bee used to extract insiights from large amouts of data. It is widly used in varius industries such as healthcare, fainance, and marketting. The potentshal of ML is enormus, and it continus to evolv and advanse. With contnued reserch and innvation, we can unlok new possiblities and advans our understatding of the world.\"\n",
    "print(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "569ab6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spelling_and_abbreviations(text):\n",
    "    # Initialize the spell checker\n",
    "    spell = Speller(lang='en')\n",
    "\n",
    "    # Initialize the enchant dictionary\n",
    "    dictionary = enchant.Dict(\"en_US\")\n",
    "\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "\n",
    "    corrected_words = []\n",
    "    for word in words:\n",
    "        # Check if the word is an abbreviation\n",
    "        if word.isupper() and len(word) > 1:\n",
    "\n",
    "            # For demonstration purposes, let's assume we don't make any changes to abbreviations\n",
    "            corrected_words.append(word)\n",
    "        else:\n",
    "            # Check if the word is misspelled\n",
    "            if not dictionary.check(word):\n",
    "                # Get the most likely correct spelling suggestion\n",
    "                corrected_word = spell(word)\n",
    "                corrected_words.append(corrected_word)\n",
    "            else:\n",
    "                corrected_words.append(word)\n",
    "\n",
    "    # Join the corrected words back into text\n",
    "    corrected_text = \" \".join(corrected_words)\n",
    "\n",
    "    return corrected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87b9fc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a paragraph containing misspelled words. The science of NLP is an important field of AI. It involves processing, understanding, and generating human language text. NLP technologies have a died range of applications, including machine translation, sentiment analysis, and information retrieval. Machine Learning is a powerful tool that can bee used to extract insights from large amounts of data. It is widely used in various industries such as healthcare, finance, and marketing. The potential of ML is enormous, and it continue to evolve and advance. With continued research and innovation, we can unlock new possibilities and advance our understanding of the world.\n"
     ]
    }
   ],
   "source": [
    "corrected_paragraph = correct_spelling_and_abbreviations(paragraph)\n",
    "print(corrected_paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097e0c16",
   "metadata": {},
   "source": [
    "**7. Removing HTML tags or other markup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d777af4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NLP, or Natural Language Processing, is a field of AI that focuses on the interaction between computers and human language. It involves analyzing, understanding, and generating natural language data. <strong>Text classification</strong>, <em>sentiment analysis</em>, and <a href=\"https://example.com\">machine translation</a> are some common NLP tasks. NLP techniques utilize <b>machine learning</b> algorithms to process and interpret language patterns. <i>Named entity recognition</i>, <u>part-of-speech tagging</u>, and <code>tokenization</code> are fundamental NLP tasks. NLP plays a significant role in various applications such as <span class=\"highlight\">chatbots</span>, <mark>voice assistants</mark>, and <del>information extraction</del>.</p>\n",
      "<p>Python provides powerful libraries like <sup>NLTK</sup> (Natural Language Toolkit) and <abbr title=\"spaCy\">spaCy</abbr> for NLP tasks. When working with text data, it's essential to remove HTML tags that might be present. Removing HTML tags can be done using regular expressions in Python.</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paragraph = \"\"\"\n",
    "NLP, or Natural Language Processing, is a field of AI that focuses on the interaction between computers and human language. It involves analyzing, understanding, and generating natural language data. <strong>Text classification</strong>, <em>sentiment analysis</em>, and <a href=\"https://example.com\">machine translation</a> are some common NLP tasks. NLP techniques utilize <b>machine learning</b> algorithms to process and interpret language patterns. <i>Named entity recognition</i>, <u>part-of-speech tagging</u>, and <code>tokenization</code> are fundamental NLP tasks. NLP plays a significant role in various applications such as <span class=\"highlight\">chatbots</span>, <mark>voice assistants</mark>, and <del>information extraction</del>.</p>\n",
    "<p>Python provides powerful libraries like <sup>NLTK</sup> (Natural Language Toolkit) and <abbr title=\"spaCy\">spaCy</abbr> for NLP tasks. When working with text data, it's essential to remove HTML tags that might be present. Removing HTML tags can be done using regular expressions in Python.</p>\n",
    "\"\"\"\n",
    "print(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5323ba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    clean_text = re.sub('<.*?>', '', text)  # Removes all HTML tags\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebf6d0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NLP, or Natural Language Processing, is a field of AI that focuses on the interaction between computers and human language. It involves analyzing, understanding, and generating natural language data. Text classification, sentiment analysis, and machine translation are some common NLP tasks. NLP techniques utilize machine learning algorithms to process and interpret language patterns. Named entity recognition, part-of-speech tagging, and tokenization are fundamental NLP tasks. NLP plays a significant role in various applications such as chatbots, voice assistants, and information extraction.\n",
      "Python provides powerful libraries like NLTK (Natural Language Toolkit) and spaCy for NLP tasks. When working with text data, it's essential to remove HTML tags that might be present. Removing HTML tags can be done using regular expressions in Python.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove HTML tags using regular expressions\n",
    "clean_text = remove_html_tags(paragraph)\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffb85e9",
   "metadata": {},
   "source": [
    "**8. Parts of Speech Tagging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48b0deb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS - NOUN\n",
      "tagging - NOUN\n",
      "is - AUX\n",
      "an - DET\n",
      "important - ADJ\n",
      "task - NOUN\n",
      "in - ADP\n",
      "NLP - PROPN\n",
      ". - PUNCT\n"
     ]
    }
   ],
   "source": [
    "# Sample sentence\n",
    "sentence = \"POS tagging is an important task in NLP.\"\n",
    "\n",
    "# Process the sentence\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Print the token and POS tag\n",
    "for token in doc:\n",
    "    print(token.text, \"-\", token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9555078",
   "metadata": {},
   "source": [
    "**9. Named Entity Recognition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04c29f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama, a well-known politician, was born in Honolulu, Hawaii. He served as the 44th President of the United States of America. The White House, located in Washington, D.C., is the official residence and workplace of the President. Apple Inc. is a multinational technology company based in Cupertino, California. It designs and manufactures various electronic devices, including the iPhone and Macbook. The Eiffel Tower, a famous landmark in Paris, France, attracts millions of tourists every year. The Olympic Games, held every four years, bring together athletes from different nations. 'Harry Potter and the Sorcerer's Stone' is a popular fantasy novel written by J.K. Rowling. The Constitution of the United States is a fundamental law that governs the country. English is a widely spoken language around the world. The event will take place on July 15th, 2022. The meeting is scheduled for 9:30 AM. The price of the product is $99.99. The distance between the two cities is 200 kilometers. This is the first edition of the book. The team won by a score of 3-1.\n"
     ]
    }
   ],
   "source": [
    "text = \"Barack Obama, a well-known politician, was born in Honolulu, Hawaii. He served as the 44th President of the United States of America. The White House, located in Washington, D.C., is the official residence and workplace of the President. Apple Inc. is a multinational technology company based in Cupertino, California. It designs and manufactures various electronic devices, including the iPhone and Macbook. The Eiffel Tower, a famous landmark in Paris, France, attracts millions of tourists every year. The Olympic Games, held every four years, bring together athletes from different nations. 'Harry Potter and the Sorcerer's Stone' is a popular fantasy novel written by J.K. Rowling. The Constitution of the United States is a fundamental law that governs the country. English is a widely spoken language around the world. The event will take place on July 15th, 2022. The meeting is scheduled for 9:30 AM. The price of the product is $99.99. The distance between the two cities is 200 kilometers. This is the first edition of the book. The team won by a score of 3-1.\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46a24365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama PERSON\n",
      "Honolulu GPE\n",
      "Hawaii GPE\n",
      "44th ORDINAL\n",
      "the United States of America GPE\n",
      "The White House ORG\n",
      "Washington GPE\n",
      "D.C. GPE\n",
      "Apple Inc. ORG\n",
      "Cupertino GPE\n",
      "California GPE\n",
      "Macbook PRODUCT\n",
      "The Eiffel Tower FAC\n",
      "Paris GPE\n",
      "France GPE\n",
      "millions CARDINAL\n",
      "The Olympic Games EVENT\n",
      "every four years DATE\n",
      "Harry Potter PERSON\n",
      "the Sorcerer's Stone' ORG\n",
      "J.K. Rowling PERSON\n",
      "the United States GPE\n",
      "English LANGUAGE\n",
      "July 15th, 2022 DATE\n",
      "9:30 AM TIME\n",
      "99.99 MONEY\n",
      "two CARDINAL\n",
      "200 kilometers QUANTITY\n",
      "first ORDINAL\n",
      "3 CARDINAL\n"
     ]
    }
   ],
   "source": [
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the entities in the document\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf9f833",
   "metadata": {},
   "source": [
    "**10. Sentiment Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bf2f400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The ground staff were not helpful. Felt like...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0    The ground staff were not helpful. Felt like..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"customer_reviews.csv\")\n",
    "df[\"reviews\"] = df[\"reviews\"].str.split(\"|\").str.get(1)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9b7ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to categorize polarity\n",
    "def categorize_polarity(polarity):\n",
    "    if polarity > 0.05:\n",
    "        return 'Positive'\n",
    "    elif polarity < -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Function to categorize subjectivity\n",
    "def categorize_subjectivity(subjectivity):\n",
    "    if subjectivity > 0.7:\n",
    "        return 'Highly Subjective'\n",
    "    elif subjectivity > 0.3:\n",
    "        return 'Subjective'\n",
    "    else:\n",
    "        return 'Objective'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d4de6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply sentiment analysis to the text column\n",
    "df['polarity'] = df[\"reviews\"].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "df['subjectivity'] = df[\"reviews\"].apply(lambda x: TextBlob(x).sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3270ffaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize polarity and subjectivity\n",
    "df['polarity_category'] = df['polarity'].apply(categorize_polarity)\n",
    "df['subjectivity_category'] = df['subjectivity'].apply(categorize_subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3da4fcac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Polarity  Reviews\n",
       "0  Positive      551\n",
       "1   Neutral      230\n",
       "2  Negative      219"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarity_counts = df[\"polarity_category\"].value_counts().to_frame().reset_index()\n",
    "polarity_counts.columns = [\"Polarity\", \"Reviews\"]\n",
    "polarity_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37892be",
   "metadata": {},
   "source": [
    "**11. Text Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b7eeab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['reviews']  # Textual data\n",
    "\n",
    "# Extract features from text using TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "\n",
    "# Perform anomaly detection using Isolation Forest\n",
    "isolation_forest = IsolationForest(contamination=0.01)  # Adjust contamination parameter as needed\n",
    "isolation_forest.fit(X_vec)\n",
    "\n",
    "# Predict the outliers (spam-like texts)\n",
    "outlier_preds = isolation_forest.predict(X_vec)\n",
    "\n",
    "# Add the predicted labels to the dataset\n",
    "df['spam'] = outlier_preds\n",
    "\n",
    "df[\"spam\"].replace({1: \"no spam\", -1: \"spam\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5fca7c",
   "metadata": {},
   "source": [
    "**12. Language Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "08dc4d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: Two years ago, the U.S. government began to investigate the use of drones in Yemen. The U.S. government has been accused of using drones to kill civilians in Yemen, and the U.S. has been accused of using drones\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained GPT model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Example prompt\n",
    "prompt = \"Two years ago\"\n",
    "\n",
    "# Tokenize the prompt\n",
    "input_ids = tokenizer.encode(prompt, add_special_tokens=True, truncation=True, padding='longest', return_tensors='pt')\n",
    "\n",
    "# Generate text using the GPT model\n",
    "output = model.generate(input_ids, max_length=50, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "# Decode the generated text\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"Generated text: {generated_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6487cd4",
   "metadata": {},
   "source": [
    "**13. Word Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e6e9afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>polarity_category</th>\n",
       "      <th>subjectivity_category</th>\n",
       "      <th>spam</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The ground staff were not helpful. Felt like...</td>\n",
       "      <td>-0.216667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Objective</td>\n",
       "      <td>no spam</td>\n",
       "      <td>[-2.1799493, 1.78598, -2.9814925, -0.18267782,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Second time BA Premium Economy in a newer ai...</td>\n",
       "      <td>0.388106</td>\n",
       "      <td>0.622727</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Subjective</td>\n",
       "      <td>no spam</td>\n",
       "      <td>[-2.024629, -0.37910125, -1.6072346, 0.2592054...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They changed our Flights from Brussels to Lo...</td>\n",
       "      <td>-0.119583</td>\n",
       "      <td>0.480833</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Subjective</td>\n",
       "      <td>no spam</td>\n",
       "      <td>[-1.2155534, 1.6921389, -3.7904077, -0.6767871...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  polarity  subjectivity  \\\n",
       "0    The ground staff were not helpful. Felt like... -0.216667      0.266667   \n",
       "1    Second time BA Premium Economy in a newer ai...  0.388106      0.622727   \n",
       "2    They changed our Flights from Brussels to Lo... -0.119583      0.480833   \n",
       "\n",
       "  polarity_category subjectivity_category     spam  \\\n",
       "0          Negative             Objective  no spam   \n",
       "1          Positive            Subjective  no spam   \n",
       "2          Negative            Subjective  no spam   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-2.1799493, 1.78598, -2.9814925, -0.18267782,...  \n",
       "1  [-2.024629, -0.37910125, -1.6072346, 0.2592054...  \n",
       "2  [-1.2155534, 1.6921389, -3.7904077, -0.6767871...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "embeddings = []\n",
    "for text in df['reviews']:\n",
    "    doc = nlp(text)\n",
    "    text_embedding = doc.vector\n",
    "    embeddings.append(text_embedding)\n",
    "\n",
    "df['embeddings'] = embeddings\n",
    "df.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
