{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce24d23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the name of Allah, the Most Benoficient, the Most Merciful\n"
     ]
    }
   ],
   "source": [
    "Tasmia = \"In the name of Allah, the Most Benoficient, the Most Merciful\"\n",
    "print(Tasmia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4ae918",
   "metadata": {},
   "source": [
    "### Import Librarires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "597d7068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc37df1",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f37c6344",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['So if a photon is directed through a plane with two slits in it and either slit is observed it will not go through both slits. If it’s unobserved it will, however, if it’s observed after it’s left the plane but before it hits its target, it will not have gone through both slits.''Hello, female children. Allow me to inspire you with a story about a great female scientist. Polish-born, French-educated Madame Curie. Co-discoverer of radioactivity, she was a hero of science, until her hair fell out, her vomit and stool became filled with blood, and she was poisoned to death by her own discovery. With a little hard work, I see no reason why that can’t happen to any of you. Are we done? Can we go?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "521388c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54, 55, 56, 57, 58, 59, 11, 60, 21, 22,  1, 61, 11, 62, 63, 12, 64,\n",
       "       65, 66, 12, 67,  7, 68, 69, 70,  3, 71,  7, 21, 22, 72, 10, 73, 74,\n",
       "       12, 75, 76,  3,  1, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 10,\n",
       "       88, 11, 20, 89, 23, 90, 91, 23, 17])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the dictionary of indexes\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# Change texts into sequence of indexes\n",
    "text_numeric = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# Pad the sequences\n",
    "text_pad = pad_sequences(text_numeric, 60)\n",
    "text_pad[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a770e768",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5b1e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=128, input_shape=(None, 1)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Load pre-trained weights\n",
    "model.load_weights('model_weights.h5')\n",
    "\n",
    "# Method '.evaluate()' shows the loss and accuracy\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Loss: {0} \\nAccuracy: {1}\".format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36312001",
   "metadata": {},
   "source": [
    "### Exploding gradient problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4738b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Keras model with one hidden Dense layer\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=20, activation='relu', kernel_initializer=he_uniform(seed=42)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile and fit the model\n",
    "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01, momentum=0.9))\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, verbose=0)\n",
    "\n",
    "# See Mean Square Error for train and test data\n",
    "train_mse = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Print the values of MSE\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38990d13",
   "metadata": {},
   "source": [
    "**Clip value avoid exploding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f86358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Keras model with one hidden Dense layer\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=20, activation='relu', kernel_initializer=he_uniform(seed=42)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile and fit the model\n",
    "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01, momentum=0.9, clipvalue=3.0))\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, verbose=0)\n",
    "\n",
    "# See Mean Square Error for train and test data\n",
    "train_mse = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Print the values of MSE\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b23d877",
   "metadata": {},
   "source": [
    "### Vanishing gradient problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85c2dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=600, input_shape=(None, 1)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Load pre-trained weights\n",
    "model.load_weights('model_weights.h5')\n",
    "\n",
    "# Plot the accuracy x epoch graph\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7e0d13",
   "metadata": {},
   "source": [
    "### Stacking RNN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4315ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LSTM layer\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=128, input_shape=(None, 1), return_sequences=True))\n",
    "model.add(LSTM(units=128, return_sequences=True))\n",
    "model.add(LSTM(units=128, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Load pre-trained weights\n",
    "model.load_weights('lstm_stack_model_weights.h5')\n",
    "\n",
    "print(\"Loss: %0.04f\\nAccuracy: %0.04f\" % tuple(model.evaluate(X_test, y_test, verbose=0)))f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef75f687",
   "metadata": {},
   "source": [
    "### Number of parameters comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc5fc783",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocabulary_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4832/1542496966.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Create a model with embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"emb_model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocabulary_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwordvec_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msentence_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGRU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vocabulary_size' is not defined"
     ]
    }
   ],
   "source": [
    "# Import the embedding layer\n",
    "from keras.layers import Embedding\n",
    "\n",
    "# Create a model with embeddings\n",
    "model = Sequential(name=\"emb_model\")\n",
    "model.add(Embedding(input_dim=vocabulary_size + 1, output_dim=wordvec_dim, input_length=sentence_len, trainable=True))\n",
    "model.add(GRU(128))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the summaries of the one-hot model\n",
    "model_onehot.summary()\n",
    "\n",
    "# Print the summaries of the model with embeddings\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf70d91",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f04793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the glove pre-trained vectors\n",
    "glove_matrix = load_glove('glove_200d.zip')\n",
    "\n",
    "# Create a model with embeddings\n",
    "model = Sequential(name=\"emb_model\")\n",
    "model.add(Embedding(input_dim=vocabulary_size + 1, output_dim=wordvec_dim, \n",
    "                    embeddings_initializer=Constant(glove_matrix), \n",
    "                    input_length=sentence_len, trainable=False))\n",
    "model.add(GRU(128))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the summaries of the model with embeddings\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5c4c3b",
   "metadata": {},
   "source": [
    "### Embeddings improves performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad61bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with embedding\n",
    "model = Sequential(name=\"emb_model\")\n",
    "model.add(Embedding(input_dim=max_vocabulary, output_dim=wordvec_dim, input_length=max_len))\n",
    "model.add(SimpleRNN(units=128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Load pre-trained weights\n",
    "model.load_weights('embedding_model_weights.h5')\n",
    "\n",
    "# Evaluate the models' performance (ignore the loss value)\n",
    "_, acc_embeddings = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Print the results\n",
    "print(\"SimpleRNN model's accuracy:\\t{0}\\nEmbeddings model's accuracy:\\t{1}\".format(acc_simpleRNN, acc_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9715794e",
   "metadata": {},
   "source": [
    "### Better sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae2b7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size, wordvec_dim, trainable=True, input_length=max_text_len))\n",
    "model.add(LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.15))\n",
    "model.add(LSTM(64, return_sequences=False, dropout=0.2, recurrent_dropout=0.15))\n",
    "model.add(Dense(16))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Load pre-trained weights\n",
    "model.load_weights('model_weights.h5')\n",
    "\n",
    "# Print the obtained loss and accuracy\n",
    "print(\"Loss: {0}\\nAccuracy: {1}\".format(*model.evaluate(X_test, y_test, verbose=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c66c2ea",
   "metadata": {},
   "source": [
    "### Using the CNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863f697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model summary\n",
    "model_cnn.summary()\n",
    "\n",
    "# Load pre-trained weights\n",
    "model_cnn.load_weights('model_weights.h5')\n",
    "\n",
    "# Evaluate the model to get the loss and accuracy values\n",
    "loss, acc = model_cnn.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Print the loss and accuracy obtained\n",
    "print(\"Loss: {0}\\nAccuracy: {1}\".format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e708b0",
   "metadata": {},
   "source": [
    "### Prepare label vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fa77c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the numerical ids of column label\n",
    "numerical_ids = df.label.cat.codes\n",
    "\n",
    "# Print initial shape\n",
    "print(numerical_ids.shape)\n",
    "print(numerical_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d578589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the numerical ids of column label\n",
    "numerical_ids = df.label.cat.codes\n",
    "\n",
    "# Print initial shape\n",
    "print(numerical_ids.shape)\n",
    "\n",
    "# One-hot encode the indexes\n",
    "Y = to_categorical(numerical_ids)\n",
    "\n",
    "# Check the new shape of the variable\n",
    "print(Y.shape)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d62ece",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2232399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec model\n",
    "w2v_model = Word2Vec.load(\"bigbang_word2vec.model\")\n",
    "\n",
    "# Selected words to check similarities\n",
    "words_of_interest = ['bazinga', 'penny', 'universe', 'spock', 'brain']\n",
    "\n",
    "# Compute top 5 similar words for each of the words of interest\n",
    "top5_similar_words = []\n",
    "for word in words_of_interest:\n",
    "    top5_similar_words.append(\n",
    "      {word: [item[0] for item in w2v_model.wv.most_similar([word], topn=5)]}\n",
    "    )\n",
    "\n",
    "# Print the similar words\n",
    "print(top5_similar_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde2139d",
   "metadata": {},
   "source": [
    "### Classifying News Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a361898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change text for numerical ids and pad\n",
    "X_novel = tokenizer.texts_to_sequences(news_novel.data)\n",
    "X_novel = pad_sequences(X_novel, maxlen=400)\n",
    "\n",
    "# One-hot encode the labels\n",
    "Y_novel = to_categorical(news_novel.target)\n",
    "\n",
    "# Load the model pre-trained weights\n",
    "model.load_weights('classify_news_weights.h5')\n",
    "\n",
    "# Evaluate the model on the new dataset\n",
    "loss, acc = model.evaluate(X_novel, Y_novel, batch_size=64)\n",
    "\n",
    "# Print the loss and accuracy obtained\n",
    "print(\"Loss:\\t{0}\\nAccuracy:\\t{1}\".format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a495c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probabilities for each class\n",
    "pred_probabilities = model.predict_proba(X_test)\n",
    "\n",
    "# Thresholds at 0.5 and 0.8\n",
    "y_pred_50 = [np.argmax(x) if np.max(x) >= 0.5 else DEFAULT_CLASS for x in pred_probabilities]\n",
    "y_pred_80 = [np.argmax(x) if np.max(x) >= 0.8 else DEFAULT_CLASS for x in pred_probabilities]\n",
    "\n",
    "trade_off = pd.DataFrame({\n",
    "    'Precision_50': precision_score(y_true, y_pred_50, average=None), \n",
    "    'Precision_80': precision_score(y_true, y_pred_80, average=None), \n",
    "    'Recall_50': recall_score(y_true, y_pred_50, average=None), \n",
    "    'Recall_80': recall_score(y_true, y_pred_80, average=None)}, \n",
    "  index=['Class 1', 'Class 2', 'Class 3'])\n",
    "\n",
    "print(trade_off)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
